-> DATA PREPROCESSING

1.checking missing values

IN [] : data.isnull().sum()
handling missing data

#filling columns with 0
data['columns'].fillna(0,inplace=True)

# If there are missing values, you can impute them. For numeric columns, you can use mean imputation:
imputer = SimpleImputer(strategy='mean')
data['numeric_column'] = imputer.fit_transform(data['numeric_column'].values.reshape(-1, 1))

# For categorical columns, you can use mode imputation:
imputer = SimpleImputer(strategy='most_frequent')
data['categorical_column'] = imputer.fit_transform(data['categorical_column'].values.reshape(-1, 1))
2.Converting categorical variables into numerical format is a common preprocessing step in machine learning. There are two common methods for doing this: one-hot encoding and label encoding.

Label Encoding

from sklearn.preprocessing import LabelEncoder

# Create a sample DataFrame
import pandas as pd
data = pd.DataFrame({'Category': ['A', 'B', 'A', 'C', 'B', 'A']})

# Initialize the LabelEncoder
label_encoder = LabelEncoder()

# Apply label encoding to the 'Category' column
data['Category_encoded'] = label_encoder.fit_transform(data['Category'])

print(data)
  Category  Category_encoded
0        A                 0
1        B                 1
2        A                 0
3        C                 2
4        B                 1
5        A                 0
One-Hot Encoding

# Create a sample DataFrame
import pandas as pd
data = pd.DataFrame({'Category': ['A', 'B', 'A', 'C', 'B', 'A']})

# Apply one-hot encoding to the 'Category' column
data = pd.get_dummies(data, columns=['Category'], prefix='Category')

print(data)
   Category_A  Category_B  Category_C
0           1           0           0
1           0           1           0
2           1           0           0
3           0           0           1
4           0           1           0
5           1           0           0
3.Normalizing or scaling numerical features

Min-Max Scaling:

from sklearn.preprocessing import MinMaxScaler

# Create a sample DataFrame with a numeric column 'Feature'
import pandas as pd
data = pd.DataFrame({'Feature': [10, 20, 30, 40, 50]})

# Initialize the MinMaxScaler
scaler = MinMaxScaler()

# Apply Min-Max scaling to the 'Feature' column
data['Feature_scaled'] = scaler.fit_transform(data[['Feature']])

print(data)
   Feature  Feature_scaled
0       10            0.00
1       20            0.25
2       30            0.50
3       40            0.75
4       50            1.00
Standardization (Z-score Scaling):

from sklearn.preprocessing import StandardScaler

# Create a sample DataFrame with a numeric column 'Feature'
import pandas as pd
data = pd.DataFrame({'Feature': [10, 20, 30, 40, 50]})

# Initialize the StandardScaler
scaler = StandardScaler()

# Apply standardization to the 'Feature' column
data['Feature_standardized'] = scaler.fit_transform(data[['Feature']])

print(data)
   Feature  Feature_standardized
0       10             -1.414214
1       20             -0.707107
2       30              0.000000
3       40              0.707107
4       50              1.414214
 
